{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [ 머신러닝 분석 프로세스 ]\n",
    "1) 데이터 확인 : 연속형, 범주형, 회귀, 분류, 비지도\n",
    "2) 데이터 분할 : 학습/검증/평가세트, 교차검증 방법\n",
    "3) 전처리 : 정규화, 표준화, 결측/이상치 처리\n",
    "4) 모델학습 : 회귀, 분류, 비지도, 하이퍼파라미터 조절\n",
    "5) 성능평가 : 분석 정확도 확인, 알고리즘 성능 제시"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) 성능평가 기법\n",
    "모델 예측성능을 평가하는 것은 결국 학습모델이 실젯값을 얼마나 정확하게 맞추었는지를 나타내는 것이다. 일반적으로 분석 알고리즘이 회귀분석인지 분류분석인지에 따른 성능평가지표(Evaluation Metric)로 평가할 수 있다.\n",
    "\n",
    "- 회귀분석 (MAE, MSE, RMSE, MSLE, MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE(Mean Absoulte Error)\n",
    "# 실제값과 예측값의 차이를 절댓값으로 변환하여 평균한 것\n",
    "# 에러 크기가 크대로 반영됨, 이상치에 영향을 받음\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "# MSE(Mean Squared Error)\n",
    "# 실제값과 예측값의 차이를 제곱해 평균한 것\n",
    "# 실제값과 예측값 차이의 면적 합을 의미함, 특이값이 존재하면 수치가 증가함\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "# RMSE(Root Mean Squared Error)\n",
    "# 실제값과 예측값의 차이를 제곱해 평균한 것에 루트를 씌운 것\n",
    "# 에러에 제곱을 하면 에러가 클수록 그에 따른 가중치가 높이 반영됨,\n",
    "# 이때 손실이 기하급수적으로 증가하는 상황에서 실제 오류평균보다 값이 더 커지지 않도록 상쇄하기 위해 사용\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "# MSLE(Mean Squared Log Error)\n",
    "# 실제값과 예측값의 차이를 제곱해 평균한 것에 로그를 적용한 것\n",
    "# RMSE같이 손실이 기하급수적으로 증가하는 상황에서 실제 오류평균보다 값이 더 커지지 않도록 상쇄하기 위해 사용\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "mse = mean_squared_log_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "# MAPE(Mean Absolute Percentage Error)\n",
    "# MAE를 퍼센트로 변환한 것\n",
    "# 오차가 예측값에서 차지하는 정도를 나타냄\n",
    "import numpy as np\n",
    "def MAPE(y_test, y_pred):\n",
    "  mape = np.mean(np.abs((y_test - y-pred)/y_test))*100\n",
    "  return mape\n",
    "\n",
    "mape = MAPE(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류분석 (정확도, 혼동행렬, 정밀도/재현율, F1 Score, ROC 곡선, AUC 스코어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도(Accuracy)\n",
    "# 실제 데이터에서 예측 데이터가 얼마나 같은지 판단하는 지표\n",
    "# 예측값과 동일한 데이터 수 / 전체 예측데이터 건수\n",
    "# 데이터 구성에 따라 머신러닝 모델의 성능을 왜곡할 가능성이 있기 때문에 한계점 보완을 위해 여러가지 분류지표가 함께 고려되어야 함\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 혼동행렬(Confusion Matrix)\n",
    "# 이진분류 예측오류가 얼마인지, 어떤 유형의 예측오류가 발생하고 있는지 나타내는 지표로 정확도 한계점 보완을 위해 활용할 수 있다.\n",
    "# 앞의 데이터불균형문제처리의 혼동행렬 개념 참고\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 정밀도(Precision) = TP/(FP + TP)\n",
    "# Positive 데이터 예측에 집중한 성능평가지표 : Positive로 예측한 것들 중 실제로도 P인 것들의 비율\n",
    "# 실제 Negative인 데이터를 Positive로 잘못 예측했을 때 큰 영향이 발생하기 때문에 정밀도가 상대적인 중요성을 가진다.\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 재현율(Recall)= 민감도(Sensitivity) = TP = (FN + TP)    = TPR\n",
    "# 실제 Positive인 것들 중 P로 예측한 것들의 비율\n",
    "# 실제 Positive인 데이터를 Negative로 잘못 예측했을 때 큰 영향이 발생하기 때문에 재현율이 상대적인 중요성을 가진다.\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><팁></b> Trade-off(트레이드오프)\n",
    "\n",
    "분류결정임계값(Threshold)을 조정함으로써 정밀도 똔느 재현율의 수치를 조절할 수 있다. 하지만 이 둘은 상충관계인 성능평가지표이기 때문에 한쪽을 강제로 높이면 다른 하나의 수치가 떨어지게 된다. 분석 상황에 따라 둘 중 하나에 중요도를 부여해 임계값을 조절할 수 있지만, 정밀도와 재현율 중 하나만을 강조해서는 안된다. 두 수치가 적절한 조화를 이루어 종합적으로 분류모델 성능을 평가해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score : 실제 Positive인 것들 중 P로 예측한 것들의 비율\n",
    "# 정밀도와 재현율이 어느 한 쪽으로 치우치지 않고 적절한 조화를 이룰 때 상대적으로 높은 수치를 나타냄\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# ROC Curve\n",
    "# 이진 분류모델의 주요 성능평가지표\n",
    "# FPR(False Positive Rate)(_x축)이 변할때 TPR(True Positive Rate)(_y축)이 변하는 것을 나타내는 곡선\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred, pos_label=1)   # FPR, TPR, 임계값 할당\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "\n",
    "# AUC Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) 기초 분석 프로세스 (ex.regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 데이터 확인\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_boston\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m boston \u001b[39m=\u001b[39m load_boston()\n",
      "File \u001b[1;32mc:\\Users\\heo\\.conda\\envs\\adp\\lib\\site-packages\\sklearn\\datasets\\__init__.py:156\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mload_boston\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    106\u001b[0m     msg \u001b[39m=\u001b[39m textwrap\u001b[39m.\u001b[39mdedent(\n\u001b[0;32m    107\u001b[0m         \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mglobals\u001b[39m()[name]\n",
      "\u001b[1;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인  --- boston 데이터 없어짐\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "price = boston.target\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['PRICE'] = price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
